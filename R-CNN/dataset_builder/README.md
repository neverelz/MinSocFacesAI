# Структура для сбора и нормалтзации датасетов из архивов
#### (Ибо можно очент легко закончиться, если делать се это ручками)

==============================================================================

dataset_builder/
  scripts/
    utils_common.py
    extract_archives.py
    class_report.py
    check.py
    shrink_filenames_in_place.py
    merge_coco.py
    audit_coco_dataset.py
  configs/
    class_map.json            # создание/редакция после отчёта
  README.md

==============================================================================
## extract_archives.py -> class_report.py -> merge_coco.py

### extract_archives.py распоковывает архивы в папке(детекция и сегментация распоковываются отдельно, иначе просто сливаются файлами в один датасет(а так не надо))

-----------------------------------------------------------------------------------------------------------
---------------------------------------------------------
Запуск extract_archives.py 
### python R-CNN/dataset_builder/scripts/extract_archives.py --root R-CNN/AllMVPdatasets/detection --work R-CNN/dataset_builder/work

- --root # путь к папке с архивами 
- --work папка сохранения развернутых датасетов
----------------------------------------------------------
class_report.py вытаскивает из аннотаций классы, их названия, айдишники, количество элементов и путь к папке с даннымми и состовляет csv файл(для маппинга)
-----------------------------------------------------------
* Запуск class_report.py
python R-CNN/dataset_builder/scripts/class_report.py --extracted R-CNN/dataset_builder/work/_extracted --out R-CNN/dataset_builder/work/reports

--extracted # Ввод - папка с датасетами
--out #Вывод - папка с отчетом по содержимому датасетов
-------------------------------------------------------------
Далее составляется файл class_map.jsom, все классы нормалицуются и приходят к общему списку(пока ручками)
-------------------------------------------------------------------------------------------------------

Cheak.py - короткая проверка насколько хорошо конфиг покрывает старые классы(если ли имена по которым изменяются классы)
-----------------------------------------------------------
python R-CNN/dataset_builder/scripts/check.py
-----------------------------------------------------------------

Часто возникали 2 ошибки 
1) слишком длинный путь+название файла (больше 255байт)  (/home/user/_extracted/stationary/Stationery_v3i_coco/train/NBX-Professional-Compass-Mechanical-Pencil-Math-Geometry-Drawing-Tools-0-7mm-Leads-6-Erasers-Ruler-Stationery-Supplies-Students-Teachers-Designers-Wo_36f88ae7-b964-41e8-9ec6-95e17fee47f6-8b7337dddd37263c5100bb5be92f86ef_webp.rf.be50b148c1e983bc22239db5091c5dab.jpg)
2) Файлы не получалось переименовать и сократить
3) Было расхождение имен в анатациях и в конфиге из-за чего на выходе финальная анатация оставалась пустой

Решено это было во-первых после выноса ключевой директории в корневую папку юзер (/home/user/_extracted вместо /home/user/Documents/PycharmProjects/MinSocFacesAI/R-CNN/dataset_builder/work/_extracted)
Потом с помощью скрипта [shrink_filenames_in_place.py] классы были нормализованы, приведены к именам в аннотациях, а длинные имена сокращены)
_____________________________________________________________________________________________________________________________________
Запуск [shrink_filenames_in_place.py]

#python R-CNN/dataset_builder/scripts/shrink_filenames_in_place.py --root /home/user/_extracted --max-len 128 

--root /home/user/_extracted  #Папка с набором датасетов
--max-len 128   #Максимальная длина файла после переименования


Важно работать с одним _extracted (/home/user/_extracted), потому что, о господи, во время отладки я создала много копий и в итоге изменяла данные в одном, а тестировала другой ахахахаха
(Примерный результат: Renamed basenames: 0 — значит, в самих папках со сплитами сейчас нет файлов, чьи basename длиннее лимита (128), т. е. переименовывать уже нечего.
Fixed filenames in annotations: 157 — в 157 записях COCO мы обновили images[].file_name, чтобы они совпадали с фактическими (укороченными) именами файлов. Это как раз то, что мешало мерджу.)
=================================================================================
--------------------------------------------------------------------------------------------------------------------------------------
Запуск [compare_map_vs_archive.py]

### python R-CNN/dataset_builder/scripts/compare_map_vs_archive.py --map R-CNN/class_map_old.json --csv R-CNN/dataset_builder/work/reports/classes_by_archive.csv --out R-CNN/dataset_builder/work/reports/csv --ds-key-mode tail2 --col-archive archive_dir --col-class category_name_from_coco

--map R-CNN/class_map_old.json   #путь к конфигу
--csv R-CNN/dataset_builder/work/reports/classes_by_archive.csv  #Путь к архиву
--out R-CNN/dataset_builder/work/reports/csv   #куда сохраняется
--ds-key-mode tail2   #Показывает насколько далеко нужно зайти внутрь папки /.../med/scissors/train/..../  Тут scissors как раз 2 (tail2), был бы 3, был бы tail3
--col-archive archive_dir  #Коллонка с названием 
--col-class category_name_from_coco  #название колонки в csv файле(получен после [class_report.py]) выполняется после [shrink_filenames_in_place.py] потомы что там классы нормализуются и подстраиваются под те, что в архиве. Если запустить этот скрипт до, возможно список unmarked увеличится в несколько раз. У меня по моему было 179~

Сопостовляет названия колонок(в архиве "name"? в конфиге "category_name_from_coco") и проверяет все ли значения есть в конфиге, составляет статистику по классам, создает два файла, первый со списком игнорируемых классов, другой с непомеченными(не в конфиге)

Божественный код для безболезненного маппинга
------------------------------------------------------------------------------------------
Далее запуск merge_coco.py

Данный скрипт вытаскивает все фотографии и анотации со всех файлов, переписывает все под единый формат,
переписывает аннотации и объеденяет все датасеты в 1, и разделяя на train, val и test
----------------------------------------------------------------------------
Запуск [merge_coco.py]

python -u R-CNN/dataset_builder/scripts/merge_coco.py --extracted /home/user/_extracted --out /home/user/mrgv2 --mode unified --split 0.8 0.1 0.1 --map R-CNN/dataset_builder/configs/class_map_old.json --dedup --task detection --short-names --verbose 

=================================================================================
Далее аудит с помощью [audit_coco_dataset.py]
- скрипт работает по корню датасета с подпапками train/, val|valid|validation/, test/;
- аккуратно проверяет существование файлов по basename (без длинных путей), чтобы не спотыкаться о «File name too long»;
- печатает краткую сводку в консоль;
- сохраняет подробные отчёты в reports_audit/ (CSV): классы и их частоты, отсутствующие файлы, изображения без аннотаций, «висячие» аннотации (на несуществующие image_id), проблемы bbox, распределения и т. п.

--------------------------------------------------------------------------------------------
Запуск [audit_coco_dataset.py]

* python R-CNN/dataset_builder/scripts/audit_coco_dataset.py --root /home/user/mrg --split-names train val test

Результат: 

[train] /home/user/mrg/train/annotations.coco.json
 images: 64656 (exist on disk: 64656, missing: 0)
 annotations: 106729 (orphan: 0, bbox_issues: 167)
 categories: 76
 images without annotations: 2613
 per-image ann count: min=1 mean=1.72 median=1 max=77
 segmentation presence: with=0 without=106729
 reports: /home/user/mrg/reports_audit

[val] /home/user/mrg/val/annotations.coco.json
 images: 8082 (exist on disk: 8082, missing: 0)
 annotations: 13203 (orphan: 0, bbox_issues: 29)
 categories: 76
 images without annotations: 346
 per-image ann count: min=1 mean=1.71 median=1.0 max=56
 segmentation presence: with=0 without=13203
 reports: /home/user/mrg/reports_audit

[test] /home/user/mrg/test/annotations.coco.json
 images: 8082 (exist on disk: 8082, missing: 0)
 annotations: 13490 (orphan: 0, bbox_issues: 31)
 categories: 75
 images without annotations: 312
 per-image ann count: min=1 mean=1.74 median=1.0 max=63
 segmentation presence: with=0 without=13490
 reports: /home/user/mrg/reports_audit



### Что в итоге
- Консольная сводка по каждому сплиту: кол-во изображений/аннотаций/классов, сколько файлов реально лежит, сколько отсутствует, проблемы bbox, «висячие» аннотации, наличие сегментаций.
- В reports_audit/:
{split}_class_counts.csv
  
{split}_missing_files.csv

{split}_orphan_annotations.csv

{split}_images_without_annotations.csv

{split}_bbox_issues.csv

{split}_per_image_ann_counts.csv

- missing_files — это несоответствия file_name ↔ фактическим именам

===============================================================================

Большая часть часть классов вдохновлялась этим списком. Пока в датаете есть лишь часть 
1) Острые/колющие/режущие
Ножи (кухонные, складные), канцелярский нож/резак, скальпели, лезвия бритв, ножницы (в т.ч. маникюрные), вилки (металл), 
шила/стилеты, циркули, металлические линейки с острой кромкой, точилки со сменными лезвиями, овощечистки, тёрки, ножи для пиццы, 
открывалки/консервные ножи, шампуры/шпажки, осколки стекла/керамики

2) Лигатурные/удушающие
Ремни, шнурки, галстуки/шарфы, шнуры от одежды, ремни/стропы сумок; проводные наушники, зарядные/сетевые/ethernet-кабели, 
удлинители; простыни/полотенца, верёвки/бечёвки/эластичные жгуты; полиэтиленовые пакеты/плёнка
(гибкие/длинные предметы создают риск образования петли) 

3) Огнеопасные/химические
Зажигалки, спички; аэрозоли (дезодорант, лак для волос); спирт/парфюм, ацетон и растворители, агрессивные чистящие средства.

4) Тупые/ударные/тяжёлые
Молотки, гаечные/разводные ключи, отвёртки, плоскогубцы/кусачки, напильники; металлические трубы/прутья/цепи, 
навесные замки, тяжёлые статуэтки/бумагодержатели.

5) Медицинские принадлежности
Шприцы и иглы (в т.ч. инсулиновые), скальпели, ланцеты, хирургические ножницы/пинцеты/зажимы, жгуты/турникеты, 
IV-линии/трубки, упаковки лекарств (флаконы/блистеры). (Большинство — предметы персонала, доступ пациентов регулируется.)

6) Канцелярия и офис
Степлеры и скобы, скрепки, кнопки-гвоздики/булавки, дыроколы; канцелярские ножи; металлические линейки; 
циркули; точилки со сменными лезвиями; сильные клеи/суперклей. 

7) Кухонные/столовые
Кухонные ножи и столовые ножи (металл), вилки; открывалки/штопоры, консервные ножи; овощечистки, 
тёрки, ножи для пиццы; шампуры/шпажки; блендеры/миксеры (ножи + кабели).

8) Личные гигиены/косметика
Бритвенные станки и сменные лезвия, маникюрные ножницы/кусачки/пилки (металл/стекло), пинцеты, шпильки/невидимки; 
аэрозольные дезодоранты/парфюмы (часто ещё и в стекле); зубная нить/ленты.

9) Электроника и кабели
Смартфоны/планшеты/ноутбуки, камеры; жёсткие диски/SD-карты; игровые контроллеры с проводом; зарядные устройства, 
удлинители, ethernet/коаксиальные кабели, проводные наушники. 
(Много где запрещена техника с доступом к интернету/камерой; кабели — типичный лигатурный риск.) 

10) Контейнеры/упаковка/материалы
Стеклянные бутылки/банки/фоторамки, керамические кружки/тарелки (осколки), жестяные банки/консервы (острые кромки), 
алюминиевая фольга, полиэтиленовые пакеты. 

11) Прочее (спорт/хобби)
Скакалки, верёвки/эспандеры, проволока/плечики из проволоки, резцы/ножи для творчества, дротики для дартса.

12) Опасные зоны/элементы среды (для детекции «зон риска»)
Крючки/вешалки/выступающие детали, где можно закрепить петлю; душевые штанги/карнизы/держатели полотенец; 
оконные ручки/решётки/петли/дверные петли; крепления телевизоров, радиаторы/трубопроводы/поручни; лестницы/балконы/балюстрады