# hardware_detection.py

import psutil
from platform_utils import get_platform_info, is_gpu_supported

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

class HardwareLevel:
    CPU_ONLY = "cpu_only"      # AMD / Intel –±–µ–∑ CUDA
    NVIDIA_GPU = "nvidia_gpu"  # –ï—Å—Ç—å CUDA

def get_cpu_info():
    cores = psutil.cpu_count(logical=False) or 2
    logical_cores = psutil.cpu_count(logical=True) or 4
    freq = psutil.cpu_freq()
    max_freq = freq.max if freq else 2000
    return {
        'physical_cores': cores,
        'logical_cores': logical_cores,
        'max_freq_mhz': max_freq
    }

def get_memory_info():
    mem = psutil.virtual_memory()
    total_gb = mem.total / (1024**3)
    return total_gb

def is_nvidia_gpu_available():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ NVIDIA GPU —á–µ—Ä–µ–∑ CUDA (—É—Å—Ç–∞—Ä–µ–≤—à–∞—è —Ñ—É–Ω–∫—Ü–∏—è)"""
    if not TORCH_AVAILABLE:
        return False, "torch not available"
    
    try:
        if torch.cuda.is_available() and torch.cuda.device_count() > 0:
            return True, torch.cuda.get_device_name(0)
    except Exception:
        pass
    return False, "No NVIDIA GPU"

def estimate_hardware_level():
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å –∞–ø–ø–∞—Ä–∞—Ç–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è —Å –∫—Ä–æ—Å—Å-–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –∫—Ä–æ—Å—Å-–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    gpu_available, gpu_name = is_gpu_supported()
    
    # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ä—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    if not gpu_available and TORCH_AVAILABLE:
        old_gpu_available, old_gpu_name = is_nvidia_gpu_available()
        if old_gpu_available:
            gpu_available, gpu_name = old_gpu_available, old_gpu_name

    if gpu_available:
        level = HardwareLevel.NVIDIA_GPU
    else:
        level = HardwareLevel.CPU_ONLY

    details = {
        'cpu_cores_physical': get_cpu_info()['physical_cores'],
        'ram_gb': round(get_memory_info(), 1),
        'gpu_available': gpu_available,
        'gpu_name': gpu_name,
        'platform': get_platform_info()['system']
    }

    return level, details

def get_optimal_settings(hardware_level):
    if hardware_level == HardwareLevel.NVIDIA_GPU:
        return {
            'process_interval_sec': 0.05,
            'camera_width': 1280,
            'camera_height': 720,
            'camera_fps': 30,
            'use_gpu': True,
            'det_size': (640, 640),
            'recog_batch_size': 8
        }
    else:  # CPU_ONLY
        return {
            'process_interval_sec': 0.35,
            'camera_width': 640,
            'camera_height': 480,
            'camera_fps': 10,
            'use_gpu': False,
            'det_size': (320, 320),      # –ú–µ–Ω—å—à–µ ‚Äî –±—ã—Å—Ç—Ä–µ–µ –Ω–∞ CPU
            'recog_batch_size': 1        # CPU –Ω–µ –ª—é–±–∏—Ç –±–æ–ª—å—à–∏–µ –±–∞—Ç—á–∏
        }

def select_hardware_level_interactive(estimated_level):
    print("\n‚öôÔ∏è  –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω —É—Ä–æ–≤–µ–Ω—å:")
    if estimated_level == HardwareLevel.NVIDIA_GPU:
        print("   ‚úÖ NVIDIA GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU")
    else:
        print("   ‚ö†Ô∏è  NVIDIA GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")

    print("   Enter ‚Äî –æ—Å—Ç–∞–≤–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å\n")
    input("üëâ –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
    return estimated_level